// Mock API responses for backend endpoints
import type { ApiResponse, GPUMetrics, GPUNode, GPUUtilization } from "./api";

export const mockGpuMetrics: ApiResponse<GPUMetrics[]> = {
  success: true,
  message: "GPU metrics retrieved successfully",
  data: [
    {
      node_name: "gpu14",
      gpu_index: 0,
      gpu_name: "NVIDIA A100",
      utilization: 85.2,
      memory_used: 32,
      memory_total: 40,
      memory_free: 8,
      memory_utilization: 80.0,
      temperature: 70.5,
      timestamp: "2025-07-26T12:00:00Z",
    },
    {
      node_name: "gpu14",
      gpu_index: 1,
      gpu_name: "NVIDIA A100",
      utilization: 90.0,
      memory_used: 36,
      memory_total: 40,
      memory_free: 4,
      memory_utilization: 90.0,
      temperature: 72.0,
      timestamp: "2025-07-26T12:00:00Z",
    },
    {
      node_name: "gpu15",
      gpu_index: 0,
      gpu_name: "NVIDIA V100",
      utilization: 55.5,
      memory_used: 10,
      memory_total: 16,
      memory_free: 6,
      memory_utilization: 62.5,
      temperature: 68.0,
      timestamp: "2025-07-26T12:00:00Z",
    },
    {
      node_name: "gpu15",
      gpu_index: 1,
      gpu_name: "NVIDIA V100",
      utilization: 60.1,
      memory_used: 12,
      memory_total: 16,
      memory_free: 4,
      memory_utilization: 75.0,
      temperature: 65.0,
      timestamp: "2025-07-26T12:00:00Z",
    },
    {
      node_name: "gpu16",
      gpu_index: 0,
      gpu_name: "NVIDIA A100",
      utilization: 78.3,
      memory_used: 30,
      memory_total: 40,
      memory_free: 10,
      memory_utilization: 75.0,
      temperature: 69.5,
      timestamp: "2025-07-26T12:00:00Z",
    },
    {
      node_name: "gpu16",
      gpu_index: 1,
      gpu_name: "NVIDIA A100",
      utilization: 92.7,
      memory_used: 38,
      memory_total: 40,
      memory_free: 2,
      memory_utilization: 95.0,
      temperature: 74.8,
      timestamp: "2025-07-26T12:00:00Z",
    },
    {
      node_name: "gpu17",
      gpu_index: 0,
      gpu_name: "NVIDIA RTX 4090",
      utilization: 95.4,
      memory_used: 22,
      memory_total: 24,
      memory_free: 2,
      memory_utilization: 91.7,
      temperature: 78.2,
      timestamp: "2025-07-26T12:00:00Z",
    },
    {
      node_name: "gpu17",
      gpu_index: 1,
      gpu_name: "NVIDIA RTX 4090",
      utilization: 67.8,
      memory_used: 16,
      memory_total: 24,
      memory_free: 8,
      memory_utilization: 66.7,
      temperature: 69.1,
      timestamp: "2025-07-26T12:00:00Z",
    },
    {
      node_name: "gpu18",
      gpu_index: 0,
      gpu_name: "NVIDIA H100",
      utilization: 88.9,
      memory_used: 68,
      memory_total: 80,
      memory_free: 12,
      memory_utilization: 85.0,
      temperature: 72.4,
      timestamp: "2025-07-26T12:00:00Z",
    },
    {
      node_name: "gpu18",
      gpu_index: 1,
      gpu_name: "NVIDIA H100",
      utilization: 42.3,
      memory_used: 28,
      memory_total: 80,
      memory_free: 52,
      memory_utilization: 35.0,
      temperature: 61.7,
      timestamp: "2025-07-26T12:00:00Z",
    },
    {
      node_name: "gpu19",
      gpu_index: 0,
      gpu_name: "NVIDIA V100",
      utilization: 73.5,
      memory_used: 12,
      memory_total: 16,
      memory_free: 4,
      memory_utilization: 75.0,
      temperature: 71.2,
      timestamp: "2025-07-26T12:00:00Z",
    },
    {
      node_name: "gpu19",
      gpu_index: 1,
      gpu_name: "NVIDIA V100",
      utilization: 29.8,
      memory_used: 4,
      memory_total: 16,
      memory_free: 12,
      memory_utilization: 25.0,
      temperature: 54.6,
      timestamp: "2025-07-26T12:00:00Z",
    },
    {
      node_name: "gpu20",
      gpu_index: 0,
      gpu_name: "NVIDIA A40",
      utilization: 82.1,
      memory_used: 38,
      memory_total: 48,
      memory_free: 10,
      memory_utilization: 79.2,
      temperature: 69.5,
      timestamp: "2025-07-26T12:00:00Z",
    },
    {
      node_name: "gpu20",
      gpu_index: 1,
      gpu_name: "NVIDIA A40",
      utilization: 14.7,
      memory_used: 4,
      memory_total: 48,
      memory_free: 44,
      memory_utilization: 8.3,
      temperature: 48.2,
      timestamp: "2025-07-26T12:00:00Z",
    },
    {
      node_name: "gpu21",
      gpu_index: 0,
      gpu_name: "NVIDIA RTX 3090",
      utilization: 99.1,
      memory_used: 23,
      memory_total: 24,
      memory_free: 1,
      memory_utilization: 95.8,
      temperature: 80.5,
      timestamp: "2025-07-26T12:00:00Z",
    },
    {
      node_name: "gpu22",
      gpu_index: 0,
      gpu_name: "NVIDIA A100",
      utilization: 12.5,
      memory_used: 5,
      memory_total: 40,
      memory_free: 35,
      memory_utilization: 12.5,
      temperature: 45.3,
      timestamp: "2025-07-26T12:00:00Z",
    },
  ],
};

export const mockGpuNodes: ApiResponse<GPUNode[]> = {
  success: true,
  message: "GPU nodes retrieved successfully",
  data: [
    {
      node_name: "gpu14",
      gpu_count: 2,
      gpu_models: ["NVIDIA A100"],
    },
    {
      node_name: "gpu15",
      gpu_count: 2,
      gpu_models: ["NVIDIA V100"],
    },
    {
      node_name: "gpu16",
      gpu_count: 2,
      gpu_models: ["NVIDIA A100"],
    },
    {
      node_name: "gpu17",
      gpu_count: 2,
      gpu_models: ["NVIDIA RTX 4090"],
    },
    {
      node_name: "gpu18",
      gpu_count: 2,
      gpu_models: ["NVIDIA H100"],
    },
    {
      node_name: "gpu19",
      gpu_count: 2,
      gpu_models: ["NVIDIA V100"],
    },
    {
      node_name: "gpu20",
      gpu_count: 2,
      gpu_models: ["NVIDIA A40"],
    },
    {
      node_name: "gpu21",
      gpu_count: 1,
      gpu_models: ["NVIDIA RTX 3090"],
    },
    {
      node_name: "gpu22",
      gpu_count: 1,
      gpu_models: ["NVIDIA A100"],
    },
  ],
};

export const mockGpuUtilization: ApiResponse<GPUUtilization[]> = {
  success: true,
  message: "GPU utilization retrieved successfully",
  data: [
    { node: "gpu14", gpu_index: 0, utilization: 85.2, timestamp: 1721995200 },
    { node: "gpu14", gpu_index: 1, utilization: 90.0, timestamp: 1721995200 },
    { node: "gpu15", gpu_index: 0, utilization: 55.5, timestamp: 1721995200 },
    { node: "gpu15", gpu_index: 1, utilization: 60.1, timestamp: 1721995200 },
    { node: "gpu16", gpu_index: 0, utilization: 78.3, timestamp: 1721995200 },
    { node: "gpu16", gpu_index: 1, utilization: 92.7, timestamp: 1721995200 },
    { node: "gpu17", gpu_index: 0, utilization: 95.4, timestamp: 1721995200 },
    { node: "gpu17", gpu_index: 1, utilization: 67.8, timestamp: 1721995200 },
    { node: "gpu18", gpu_index: 0, utilization: 88.9, timestamp: 1721995200 },
    { node: "gpu18", gpu_index: 1, utilization: 42.3, timestamp: 1721995200 },
    { node: "gpu19", gpu_index: 0, utilization: 73.5, timestamp: 1721995200 },
    { node: "gpu19", gpu_index: 1, utilization: 29.8, timestamp: 1721995200 },
    { node: "gpu20", gpu_index: 0, utilization: 82.1, timestamp: 1721995200 },
    { node: "gpu20", gpu_index: 1, utilization: 14.7, timestamp: 1721995200 },
    { node: "gpu21", gpu_index: 0, utilization: 99.1, timestamp: 1721995200 },
    { node: "gpu22", gpu_index: 0, utilization: 12.5, timestamp: 1721995200 },
  ],
};

export const mockHealthz: ApiResponse = {
  success: true,
  message: "Service is healthy",
  data: {
    status: "healthy",
    timestamp: "2025-07-26T12:00:00Z",
    version: "1.0.0",
  },
};
